{"ts": "2026-01-14T22:16:09+0300", "tool": "list", "risk": "safe", "args": {"path": "/bench/many", "recursive": false, "limit": 50, "offset": 0}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-ls", "/bench/many"], "ok": true, "exit_code": 0, "stdout": "   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_33\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_34\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_35\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_36\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_37\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_38\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_39\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_4\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_40\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_41\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_42\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_43\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_44\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_45\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_46\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_47\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_48\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_49\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_5\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_50\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_51\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_52\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_53\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_54\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_55\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_56\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_57\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_58\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_59\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_6\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_60\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_61\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_62\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_63\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_64\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_65\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_66\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_67\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_68\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_69\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_7\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_70\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_71\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_72\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_73\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_74\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_75\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_76\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_77\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_78\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_79\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_8\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_80\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_81\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_82\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_83\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_84\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_85\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_86\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_87\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:59 /bench/many/f_88\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:59 /bench/many/f_89\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_9\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:59 /bench/many/f_90\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:59 /bench/many/f_91\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:59 /bench/many/f_92\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:19:51+0300", "tool": "list", "risk": "safe", "args": {"path": "/", "recursive": false, "limit": 200, "offset": 0}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-ls", "/"], "ok": true, "exit_code": 0, "stdout": "Found 2 items\ndrwxr-xr-x   - root supergroup          0 2026-01-14 18:57 /bench\ndrwxr-xr-x   - root supergroup          0 2026-01-13 21:08 /data\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:20:01+0300", "tool": "list", "risk": "safe", "args": {"path": "/bench/many", "recursive": false, "limit": 50, "offset": 50}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-ls", "/bench/many"], "ok": true, "exit_code": 0, "stdout": "   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_33\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_34\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_35\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_36\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_37\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_38\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_39\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_4\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_40\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_41\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_42\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_43\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_44\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_45\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_46\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_47\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_48\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_49\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_5\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_50\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_51\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_52\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_53\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_54\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_55\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_56\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_57\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_58\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_59\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_6\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_60\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_61\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_62\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_63\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_64\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_65\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_66\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_67\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_68\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_69\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_7\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_70\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_71\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_72\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_73\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_74\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_75\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_76\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_77\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_78\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_79\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_8\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_80\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_81\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_82\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_83\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_84\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_85\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_86\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:58 /bench/many/f_87\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:59 /bench/many/f_88\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:59 /bench/many/f_89\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:57 /bench/many/f_9\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:59 /bench/many/f_90\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:59 /bench/many/f_91\n-rw-r--r--   2 root supergroup          0 2026-01-14 18:59 /bench/many/f_92\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:22:09+0300", "tool": "get", "risk": "safe", "args": {"hdfs_path": "/data/raw/big.bin", "local_path": "/tmp/big_dl.bin", "overwrite": false, "confirm": false}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-get", "/data/raw/big.bin", "/tmp/big_dl.bin"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "2026-01-14 19:22:08,134 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n2026-01-14 19:22:08,586 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:23:50+0300", "tool": "get", "risk": "safe", "args": {"hdfs_path": "/data/raw/big.bin", "local_path": "/tmp/big_dl2.bin", "overwrite": false, "confirm": false}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-get", "/data/raw/big.bin", "/tmp/big_dl2.bin"], "ok": false, "exit_code": 255, "stdout": "", "stderr": ".hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:822)\n\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:747)\n\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:380)\n\tat org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:644)\n\tat org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:575)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:757)\n\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)\n\tat java.io.DataInputStream.read(DataInputStream.java:100)\n\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)\n\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)\n\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)\n\tat org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:367)\n\tat org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)\n\tat org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:304)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)\n\tat org.apache.hadoop.fs.shell.Command.processArgument(Command.java:286)\n\tat org.apache.hadoop.fs.shell.Command.processArguments(Command.java:270)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)\n\tat org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)\n\tat org.apache.hadoop.fs.shell.Command.run(Command.java:177)\n\tat org.apache.hadoop.fs.FsShell.run(FsShell.java:327)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)\n\tat org.apache.hadoop.fs.FsShell.main(FsShell.java:390)\nUsage: hadoop fs [generic options]\n\t[-appendToFile <localsrc> ... <dst>]\n\t[-cat [-ignoreCrc] <src> ...]\n\t[-checksum <src> ...]\n\t[-chgrp [-R] GROUP PATH...]\n\t[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]\n\t[-chown [-R] [OWNER][:[GROUP]] PATH...]\n\t[-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]\n\t[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]\n\t[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]\n\t[-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]\n\t[-createSnapshot <snapshotDir> [<snapshotName>]]\n\t[-deleteSnapshot <snapshotDir> <snapshotName>]\n\t[-df [-h] [<path> ...]]\n\t[-du [-s] [-h] [-v] [-x] <path> ...]\n\t[-expunge [-immediate]]\n\t[-find <path> ... <expression> ...]\n\t[-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]\n\t[-getfacl [-R] <path>]\n\t[-getfattr [-R] {-n name | -d} [-e en] <path>]\n\t[-getmerge [-nl] [-skip-empty-file] <src> <localdst>]\n\t[-head <file>]\n\t[-help [cmd ...]]\n\t[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]\n\t[-mkdir [-p] <path> ...]\n\t[-moveFromLocal <localsrc> ... <dst>]\n\t[-moveToLocal <src> <localdst>]\n\t[-mv <src> ... <dst>]\n\t[-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]\n\t[-renameSnapshot <snapshotDir> <oldName> <newName>]\n\t[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]\n\t[-rmdir [--ignore-fail-on-non-empty] <dir> ...]\n\t[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]\n\t[-setfattr {-n name [-v value] | -x name} <path>]\n\t[-setrep [-R] [-w] <rep> <path> ...]\n\t[-stat [format] <path> ...]\n\t[-tail [-f] [-s <sleep interval>] <file>]\n\t[-test -[defswrz] <path>]\n\t[-text [-ignoreCrc] <src> ...]\n\t[-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]\n\t[-touchz <path> ...]\n\t[-truncate [-w] <length> <path> ...]\n\t[-usage [cmd ...]]\n\nGeneric options supported are:\n-conf <configuration file>        specify an application configuration file\n-D <property=value>               define a value for a given property\n-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.\n-jt <local|resourcemanager:port>  specify a ResourceManager\n-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster\n-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath\n-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines\n\nThe general command line syntax is:\ncommand [genericOptions] [commandOptions]\n\nUsage: hadoop fs [generic options] -get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>\n", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:25:53+0300", "tool": "get", "risk": "safe", "args": {"hdfs_path": "/data/raw/big.bin", "local_path": "/tmp/big_dl2.bin", "overwrite": false, "confirm": false}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-get", "/data/raw/big.bin", "/tmp/big_dl2.bin"], "ok": false, "exit_code": 255, "stdout": "", "stderr": "hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:822)\n\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:747)\n\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:380)\n\tat org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:644)\n\tat org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:575)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:757)\n\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)\n\tat java.io.DataInputStream.read(DataInputStream.java:100)\n\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:100)\n\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)\n\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)\n\tat org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:367)\n\tat org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)\n\tat org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:304)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)\n\tat org.apache.hadoop.fs.shell.Command.processArgument(Command.java:286)\n\tat org.apache.hadoop.fs.shell.Command.processArguments(Command.java:270)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)\n\tat org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)\n\tat org.apache.hadoop.fs.shell.Command.run(Command.java:177)\n\tat org.apache.hadoop.fs.FsShell.run(FsShell.java:327)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)\n\tat org.apache.hadoop.fs.FsShell.main(FsShell.java:390)\nUsage: hadoop fs [generic options]\n\t[-appendToFile <localsrc> ... <dst>]\n\t[-cat [-ignoreCrc] <src> ...]\n\t[-checksum <src> ...]\n\t[-chgrp [-R] GROUP PATH...]\n\t[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]\n\t[-chown [-R] [OWNER][:[GROUP]] PATH...]\n\t[-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]\n\t[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]\n\t[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]\n\t[-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]\n\t[-createSnapshot <snapshotDir> [<snapshotName>]]\n\t[-deleteSnapshot <snapshotDir> <snapshotName>]\n\t[-df [-h] [<path> ...]]\n\t[-du [-s] [-h] [-v] [-x] <path> ...]\n\t[-expunge [-immediate]]\n\t[-find <path> ... <expression> ...]\n\t[-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]\n\t[-getfacl [-R] <path>]\n\t[-getfattr [-R] {-n name | -d} [-e en] <path>]\n\t[-getmerge [-nl] [-skip-empty-file] <src> <localdst>]\n\t[-head <file>]\n\t[-help [cmd ...]]\n\t[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]\n\t[-mkdir [-p] <path> ...]\n\t[-moveFromLocal <localsrc> ... <dst>]\n\t[-moveToLocal <src> <localdst>]\n\t[-mv <src> ... <dst>]\n\t[-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]\n\t[-renameSnapshot <snapshotDir> <oldName> <newName>]\n\t[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]\n\t[-rmdir [--ignore-fail-on-non-empty] <dir> ...]\n\t[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]\n\t[-setfattr {-n name [-v value] | -x name} <path>]\n\t[-setrep [-R] [-w] <rep> <path> ...]\n\t[-stat [format] <path> ...]\n\t[-tail [-f] [-s <sleep interval>] <file>]\n\t[-test -[defswrz] <path>]\n\t[-text [-ignoreCrc] <src> ...]\n\t[-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]\n\t[-touchz <path> ...]\n\t[-truncate [-w] <length> <path> ...]\n\t[-usage [cmd ...]]\n\nGeneric options supported are:\n-conf <configuration file>        specify an application configuration file\n-D <property=value>               define a value for a given property\n-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.\n-jt <local|resourcemanager:port>  specify a ResourceManager\n-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster\n-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath\n-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines\n\nThe general command line syntax is:\ncommand [genericOptions] [commandOptions]\n\nUsage: hadoop fs [generic options] -get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>\n", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:29:04+0300", "tool": "get", "risk": "safe", "args": {"hdfs_path": "/data/raw/big.bin", "local_path": "/tmp/big_dl2.bin", "overwrite": false, "confirm": false}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-get", "/data/raw/big.bin", "/tmp/big_dl2.bin"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "2026-01-14 19:29:03,454 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n2026-01-14 19:29:03,916 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:33:45+0300", "tool": "list", "risk": "safe", "args": {"path": "/data/raw", "recursive": false, "limit": 200, "offset": 0}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-ls", "/data/raw"], "ok": true, "exit_code": 0, "stdout": "Found 3 items\n-rw-r--r--   1 root supergroup         11 2026-01-13 19:47 /data/raw/a.txt\n-rw-r--r--   2 root supergroup  314572800 2026-01-14 18:51 /data/raw/big.bin\n-rw-r--r--   1 root supergroup         21 2026-01-13 19:47 /data/raw/sample.csv\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:34:24+0300", "tool": "list", "risk": "safe", "args": {"path": "/", "recursive": false, "limit": 200, "offset": 0}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-ls", "/"], "ok": true, "exit_code": 0, "stdout": "Found 2 items\ndrwxr-xr-x   - root supergroup          0 2026-01-14 18:57 /bench\ndrwxr-xr-x   - root supergroup          0 2026-01-13 21:08 /data\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:34:59+0300", "tool": "list", "risk": "safe", "args": {"path": "/data/raw", "recursive": false, "limit": 1, "offset": 0}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-ls", "/data/raw"], "ok": true, "exit_code": 0, "stdout": "Found 3 items\n-rw-r--r--   1 root supergroup         11 2026-01-13 19:47 /data/raw/a.txt\n-rw-r--r--   2 root supergroup  314572800 2026-01-14 18:51 /data/raw/big.bin\n-rw-r--r--   1 root supergroup         21 2026-01-13 19:47 /data/raw/sample.csv\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:35:27+0300", "tool": "list", "risk": "safe", "args": {"path": "/data/raw", "recursive": false, "limit": 1, "offset": 1}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-ls", "/data/raw"], "ok": true, "exit_code": 0, "stdout": "Found 3 items\n-rw-r--r--   1 root supergroup         11 2026-01-13 19:47 /data/raw/a.txt\n-rw-r--r--   2 root supergroup  314572800 2026-01-14 18:51 /data/raw/big.bin\n-rw-r--r--   1 root supergroup         21 2026-01-13 19:47 /data/raw/sample.csv\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:35:48+0300", "tool": "stat", "risk": "safe", "args": {"path": "/data/raw/sample.csv"}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-stat", "%n|%b|%o|%r|%u|%g|%y|%F", "/data/raw/sample.csv"], "ok": true, "exit_code": 0, "stdout": "sample.csv|21|134217728|1|root|supergroup|2026-01-13 19:47:26|regular file\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:36:21+0300", "tool": "stat", "risk": "safe", "args": {"path": "/data/raw"}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-stat", "%n|%b|%o|%r|%u|%g|%y|%F", "/data/raw"], "ok": true, "exit_code": 0, "stdout": "raw|0|0|0|root|supergroup|2026-01-14 18:51:13|directory\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:38:16+0300", "tool": "mkdir", "risk": "risky", "args": {"path": "/data/a/b/c", "parents": true, "confirm": true}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-mkdir", "-p", "/data/a/b/c"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:39:20+0300", "tool": "put", "risk": "unknown", "args": {"local_path": "/tmp/a.txt", "hdfs_path": "/data/by_llm/a2.txt", "overwrite": false, "confirm": false}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-put", "/tmp/a.txt", "/data/by_llm/a2.txt"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "2026-01-14 19:39:19,755 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:40:33+0300", "tool": "put", "risk": "unknown", "args": {"local_path": "/tmp/a.txt", "hdfs_path": "/data/by_llm/a2.txt", "overwrite": true, "confirm": true}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-put", "-f", "/tmp/a.txt", "/data/by_llm/a2.txt"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "2026-01-14 19:40:32,581 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:41:43+0300", "tool": "get", "risk": "safe", "args": {"hdfs_path": "/data/raw/a.txt", "local_path": "/tmp/a_dl.txt", "overwrite": false, "confirm": false}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-get", "/data/raw/a.txt", "/tmp/a_dl.txt"], "ok": false, "exit_code": 1, "stdout": "", "stderr": "rent block Block locations: Dead nodes: . Will get new block locations from namenode and retry...\n2026-01-14 19:41:24,625 WARN hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 2207.7740269090473 msec.\n2026-01-14 19:41:26,834 WARN hdfs.DFSClient: No live nodes contain block BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 after checking nodes = [], ignoredNodes = null\n2026-01-14 19:41:26,835 INFO hdfs.DFSClient: No node available for BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 file=/data/raw/a.txt\n2026-01-14 19:41:26,835 INFO hdfs.DFSClient: Could not obtain BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...\n2026-01-14 19:41:26,835 WARN hdfs.DFSClient: DFS chooseDataNode: got # 2 IOException, will wait for 8486.969528577672 msec.\n2026-01-14 19:41:35,321 WARN hdfs.DFSClient: No live nodes contain block BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 after checking nodes = [], ignoredNodes = null\n2026-01-14 19:41:35,321 INFO hdfs.DFSClient: No node available for BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 file=/data/raw/a.txt\n2026-01-14 19:41:35,321 INFO hdfs.DFSClient: Could not obtain BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...\n2026-01-14 19:41:35,321 WARN hdfs.DFSClient: DFS chooseDataNode: got # 3 IOException, will wait for 7926.141195025589 msec.\n2026-01-14 19:41:43,251 WARN hdfs.DFSClient: No live nodes contain block BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 after checking nodes = [], ignoredNodes = null\n2026-01-14 19:41:43,251 WARN hdfs.DFSClient: Could not obtain block: BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 file=/data/raw/a.txt No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException\n2026-01-14 19:41:43,251 WARN hdfs.DFSClient: No live nodes contain block BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 after checking nodes = [], ignoredNodes = null\n2026-01-14 19:41:43,251 WARN hdfs.DFSClient: Could not obtain block: BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 file=/data/raw/a.txt No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException\n2026-01-14 19:41:43,251 WARN hdfs.DFSClient: DFS Read\norg.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 file=/data/raw/a.txt\n\tat org.apache.hadoop.hdfs.DFSInputStream.refetchLocations(DFSInputStream.java:879)\n\tat org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:862)\n\tat org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:841)\n\tat org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:567)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:757)\n\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)\n\tat java.io.DataInputStream.read(DataInputStream.java:100)\n\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)\n\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)\n\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)\n\tat org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:367)\n\tat org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)\n\tat org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:304)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)\n\tat org.apache.hadoop.fs.shell.Command.processArgument(Command.java:286)\n\tat org.apache.hadoop.fs.shell.Command.processArguments(Command.java:270)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)\n\tat org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)\n\tat org.apache.hadoop.fs.shell.Command.run(Command.java:177)\n\tat org.apache.hadoop.fs.FsShell.run(FsShell.java:327)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)\n\tat org.apache.hadoop.fs.FsShell.main(FsShell.java:390)\nget: Could not obtain block: BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 file=/data/raw/a.txt\n", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:43:23+0300", "tool": "stat", "risk": "safe", "args": {"path": "/data/raw/a.txt"}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-stat", "%n|%b|%o|%r|%u|%g|%y|%F", "/data/raw/a.txt"], "ok": true, "exit_code": 0, "stdout": "a.txt|11|134217728|1|root|supergroup|2026-01-13 19:47:24|regular file\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:44:04+0300", "tool": "get", "risk": "safe", "args": {"hdfs_path": "/data/raw/a.txt", "local_path": "/tmp/a_dl.txt", "overwrite": false, "confirm": false}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-get", "/data/raw/a.txt", "/tmp/a_dl.txt"], "ok": false, "exit_code": 1, "stdout": "", "stderr": "rent block Block locations: Dead nodes: . Will get new block locations from namenode and retry...\n2026-01-14 19:43:54,445 WARN hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 319.20477858238763 msec.\n2026-01-14 19:43:54,768 WARN hdfs.DFSClient: No live nodes contain block BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 after checking nodes = [], ignoredNodes = null\n2026-01-14 19:43:54,768 INFO hdfs.DFSClient: No node available for BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 file=/data/raw/a.txt\n2026-01-14 19:43:54,768 INFO hdfs.DFSClient: Could not obtain BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...\n2026-01-14 19:43:54,768 WARN hdfs.DFSClient: DFS chooseDataNode: got # 2 IOException, will wait for 3618.606282927145 msec.\n2026-01-14 19:43:58,390 WARN hdfs.DFSClient: No live nodes contain block BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 after checking nodes = [], ignoredNodes = null\n2026-01-14 19:43:58,390 INFO hdfs.DFSClient: No node available for BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 file=/data/raw/a.txt\n2026-01-14 19:43:58,390 INFO hdfs.DFSClient: Could not obtain BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...\n2026-01-14 19:43:58,390 WARN hdfs.DFSClient: DFS chooseDataNode: got # 3 IOException, will wait for 6146.825778130781 msec.\n2026-01-14 19:44:04,536 WARN hdfs.DFSClient: No live nodes contain block BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 after checking nodes = [], ignoredNodes = null\n2026-01-14 19:44:04,536 WARN hdfs.DFSClient: Could not obtain block: BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 file=/data/raw/a.txt No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException\n2026-01-14 19:44:04,536 WARN hdfs.DFSClient: No live nodes contain block BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 after checking nodes = [], ignoredNodes = null\n2026-01-14 19:44:04,536 WARN hdfs.DFSClient: Could not obtain block: BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 file=/data/raw/a.txt No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException\n2026-01-14 19:44:04,536 WARN hdfs.DFSClient: DFS Read\norg.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 file=/data/raw/a.txt\n\tat org.apache.hadoop.hdfs.DFSInputStream.refetchLocations(DFSInputStream.java:879)\n\tat org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:862)\n\tat org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:841)\n\tat org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:567)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:757)\n\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)\n\tat java.io.DataInputStream.read(DataInputStream.java:100)\n\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)\n\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)\n\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)\n\tat org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:367)\n\tat org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)\n\tat org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:304)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)\n\tat org.apache.hadoop.fs.shell.Command.processArgument(Command.java:286)\n\tat org.apache.hadoop.fs.shell.Command.processArguments(Command.java:270)\n\tat org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)\n\tat org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)\n\tat org.apache.hadoop.fs.shell.Command.run(Command.java:177)\n\tat org.apache.hadoop.fs.FsShell.run(FsShell.java:327)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)\n\tat org.apache.hadoop.fs.FsShell.main(FsShell.java:390)\nget: Could not obtain block: BP-18928504-172.20.0.2-1768333494866:blk_1073741825_1001 file=/data/raw/a.txt\n", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:46:00+0300", "tool": "stat", "risk": "safe", "args": {"path": "/data/by_llm/a2.txt"}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-stat", "%n|%b|%o|%r|%u|%g|%y|%F", "/data/by_llm/a2.txt"], "ok": true, "exit_code": 0, "stdout": "a2.txt|11|134217728|2|root|supergroup|2026-01-14 19:40:32|regular file\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:46:11+0300", "tool": "get", "risk": "safe", "args": {"hdfs_path": "/data/by_llm/a2.txt", "local_path": "/tmp/a2_dl.txt", "overwrite": false, "confirm": false}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-get", "/data/by_llm/a2.txt", "/tmp/a2_dl.txt"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "2026-01-14 19:46:11,363 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:47:02+0300", "tool": "get", "risk": "safe", "args": {"hdfs_path": "/data/by_llm/a2.txt", "local_path": "/tmp/a2_dl.txt", "overwrite": false, "confirm": false}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-get", "/data/by_llm/a2.txt", "/tmp/a2_dl.txt"], "ok": false, "exit_code": 1, "stdout": "", "stderr": "get: `/tmp/a2_dl.txt': File exists\n", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:47:36+0300", "tool": "get", "risk": "safe", "args": {"hdfs_path": "/data/by_llm/a2.txt", "local_path": "/tmp/a2_dl.txt", "overwrite": true, "confirm": true}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-get", "-f", "/data/by_llm/a2.txt", "/tmp/a2_dl.txt"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "2026-01-14 19:47:35,918 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:49:14+0300", "tool": "chmod", "risk": "risky", "args": {"path": "/data/raw", "mode": "755", "recursive": true, "confirm": true}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-chmod", "-R", "755", "/data/raw"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "", "user": "unknown", "before": {"path": "/data/raw", "perm": "rwxr-xr-x", "owner": "root", "group": "supergroup", "type": "directory"}, "after": {"path": "/data/raw", "perm": "rwxr-xr-x", "owner": "root", "group": "supergroup", "type": "directory"}, "diff": {"changed": false, "changes": {}}}
{"ts": "2026-01-14T22:51:49+0300", "tool": "chmod", "risk": "risky", "args": {"path": "/data/raw", "mode": "777", "recursive": true, "confirm": true}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-chmod", "-R", "777", "/data/raw"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "", "user": "unknown", "before": {"path": "/data/raw", "perm": "rwxr-xr-x", "owner": "root", "group": "supergroup", "type": "directory"}, "after": {"path": "/data/raw", "perm": "rwxrwxrwx", "owner": "root", "group": "supergroup", "type": "directory"}, "diff": {"changed": true, "changes": {"perm": ["rwxr-xr-x", "rwxrwxrwx"]}}}
{"ts": "2026-01-14T22:53:16+0300", "tool": "chown", "risk": "risky", "args": {"path": "/data/test_perm", "owner": "root", "group": null, "recursive": true, "confirm": true}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-chown", "-R", "root", "/data/test_perm"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "", "user": "unknown", "before": {"path": "/data/test_perm", "perm": "rwxrwxrwx", "owner": "root", "group": "supergroup", "type": "directory"}, "after": {"path": "/data/test_perm", "perm": "rwxrwxrwx", "owner": "root", "group": "supergroup", "type": "directory"}, "diff": {"changed": false, "changes": {}}}
{"ts": "2026-01-14T22:55:22+0300", "tool": "chown", "risk": "risky", "args": {"path": "/data/test_perm", "owner": "hdfs", "group": null, "recursive": true, "confirm": true}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-chown", "-R", "hdfs", "/data/test_perm"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "", "user": "unknown", "before": {"path": "/data/test_perm", "perm": "rwxrwxrwx", "owner": "root", "group": "supergroup", "type": "directory"}, "after": {"path": "/data/test_perm", "perm": "rwxrwxrwx", "owner": "hdfs", "group": "supergroup", "type": "directory"}, "diff": {"changed": true, "changes": {"owner": ["root", "hdfs"]}}}
{"ts": "2026-01-14T22:57:13+0300", "tool": "getquota", "risk": "safe", "args": {"path": "/data"}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-count", "-q", "/data"], "ok": true, "exit_code": 0, "stdout": "        none             inf            none             inf            7            6          314572875 /data\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:58:19+0300", "tool": "getquota", "risk": "safe", "args": {"path": "/data/raw"}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-count", "-q", "/data/raw"], "ok": true, "exit_code": 0, "stdout": "        none             inf            none             inf            1            3          314572832 /data/raw\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T22:59:41+0300", "tool": "setquota", "risk": "risky", "args": {"path": "/data/raw", "namespace_quota": 1000, "space_quota": null, "confirm": true}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfsadmin", "-setQuota", "1000", "/data/raw"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T23:00:53+0300", "tool": "getquota", "risk": "safe", "args": {"path": "/data/raw"}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-count", "-q", "/data/raw"], "ok": true, "exit_code": 0, "stdout": "        1000             996            none             inf            1            3          314572832 /data/raw\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T23:01:47+0300", "tool": "snapshot_create", "risk": "risky", "args": {"path": "/data/raw", "name": "s1", "confirm": true}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-createSnapshot", "/data/raw", "s1"], "ok": false, "exit_code": 1, "stdout": "", "stderr": "createSnapshot: Directory is not a snapshottable directory: /data/raw\n", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T23:03:59+0300", "tool": "snapshot_create", "risk": "risky", "args": {"path": "/data/raw", "name": "s1", "confirm": true}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-createSnapshot", "/data/raw", "s1"], "ok": true, "exit_code": 0, "stdout": "Created snapshot /data/raw/.snapshot/s1\n", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T23:05:14+0300", "tool": "snapshot_delete", "risk": "risky", "args": {"path": "/data/raw", "name": "s1", "confirm": true}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "dfs", "-deleteSnapshot", "/data/raw", "s1"], "ok": true, "exit_code": 0, "stdout": "", "stderr": "", "user": "unknown", "before": null, "after": null, "diff": null}
{"ts": "2026-01-14T23:06:22+0300", "tool": "balancer_trigger", "risk": "risky", "args": {"confirm": true}, "docker_cmd": ["docker", "exec", "namenode", "hdfs", "balancer"], "ok": true, "exit_code": 0, "stdout": "Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved\nThe cluster is balanced. Exiting...\nJan 14, 2026 8:06:22 PM           0                  0 B                 0 B                0 B\nJan 14, 2026 8:06:22 PM  Balancing took 633.0 milliseconds\n", "stderr": "2026-01-14 20:06:21,983 INFO balancer.Balancer: namenodes  = [hdfs://namenode:8020]\n2026-01-14 20:06:21,985 INFO balancer.Balancer: parameters = Balancer.BalancerParameters [BalancingPolicy.Node, threshold = 10.0, max idle iteration = 5, #excluded nodes = 0, #included nodes = 0, #source nodes = 0, #blockpools = 0, run during upgrade = false]\n2026-01-14 20:06:21,985 INFO balancer.Balancer: included nodes = []\n2026-01-14 20:06:21,985 INFO balancer.Balancer: excluded nodes = []\n2026-01-14 20:06:21,985 INFO balancer.Balancer: source nodes = []\n2026-01-14 20:06:22,421 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n2026-01-14 20:06:22,509 INFO balancer.Balancer: dfs.balancer.movedWinWidth = 5400000 (default=5400000)\n2026-01-14 20:06:22,509 INFO balancer.Balancer: dfs.balancer.moverThreads = 1000 (default=1000)\n2026-01-14 20:06:22,509 INFO balancer.Balancer: dfs.balancer.dispatcherThreads = 200 (default=200)\n2026-01-14 20:06:22,509 INFO balancer.Balancer: dfs.datanode.balance.max.concurrent.moves = 50 (default=50)\n2026-01-14 20:06:22,509 INFO balancer.Balancer: dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)\n2026-01-14 20:06:22,509 INFO balancer.Balancer: dfs.balancer.getBlocks.min-block-size = 10485760 (default=10485760)\n2026-01-14 20:06:22,513 INFO balancer.Balancer: dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)\n2026-01-14 20:06:22,513 INFO balancer.Balancer: dfs.blocksize = 134217728 (default=134217728)\n2026-01-14 20:06:22,530 INFO net.NetworkTopology: Adding a new node: /default-rack/172.20.0.4:9866\n2026-01-14 20:06:22,530 INFO net.NetworkTopology: Adding a new node: /default-rack/172.20.0.3:9866\n2026-01-14 20:06:22,530 INFO net.NetworkTopology: Adding a new node: /default-rack/172.20.0.5:9866\n2026-01-14 20:06:22,532 INFO balancer.Balancer: 0 over-utilized: []\n2026-01-14 20:06:22,532 INFO balancer.Balancer: 0 underutilized: []\n", "user": "unknown", "before": null, "after": null, "diff": null}
